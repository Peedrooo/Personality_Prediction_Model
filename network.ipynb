{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personality prediction model \n",
    "This notebook is used to train a model to predict the personality of a user. For see the results of each line, see the archive network on the folder draft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = str (Path(os.getcwd())) + '\\\\data\\\\data.csv' # finding database\n",
    "data = pd.read_csv(place, sep='\\t')                  # opening database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()                                    # copying database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['dateload'], axis=1, inplace=True)       # dropping dateload column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = ~( (df['IE'] == 0 ) | (df['IE'] == 3) | (df['gender'] == 0) )        # Filter for remove invalid rows in column IE and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[filt]                           # Applying filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing DataFrame\n",
    "\n",
    "intcolumns = df.columns.drop('country')\n",
    "df[intcolumns] = df[intcolumns].astype(np.int8)\n",
    "df['country'] = df['country'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding the \"country\" and \"IE\" column\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['country'] = le.fit_transform(df['country'].values)\n",
    "df['IE'] = le.fit_transform(df['IE'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting data in parameters and target\n",
    "\n",
    "X = df.iloc[:, 0:280].values        # all columns except the last one\n",
    "y = df.iloc[:,280].values           # getting the last column(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train >>\n",
      " [[-1.90397584  0.83617006  0.01460497 ... -1.19829693  1.47572684\n",
      "  -0.51535851]\n",
      " [ 0.81699383 -1.60304267 -0.10802687 ...  0.66796069 -0.66739897\n",
      "  -0.76694216]\n",
      " [ 0.81699383  1.21729705  1.41805823 ... -1.19829693 -0.66739897\n",
      "   0.23939247]\n",
      " ...\n",
      " [-1.22373342 -1.06946489 -1.63411196 ...  0.66796069  1.47572684\n",
      "   0.32325368]\n",
      " [-0.54349101  0.72183196 -0.74843758 ...  0.66796069  1.47572684\n",
      "  -0.85080338]\n",
      " [-1.22373342  0.34070497  0.91390512 ...  0.66796069 -0.66739897\n",
      "  -0.76694216]] \n",
      "X_test >>\n",
      " [[-0.54349101 -0.11664741  1.49981279 ...  0.66796069 -0.66739897\n",
      "  -0.51535851]\n",
      " [ 0.81699383 -0.15476011 -0.72118606 ...  0.66796069 -0.66739897\n",
      "  -0.68308094]\n",
      " [ 0.81699383  1.44597324  0.6141384  ...  0.66796069 -0.66739897\n",
      "   0.74255978]\n",
      " ...\n",
      " [ 0.13675141 -0.26909821 -0.42141934 ... -1.19829693 -0.66739897\n",
      "  -0.51535851]\n",
      " [ 0.81699383  0.41693037 -0.20340719 ... -1.19829693 -0.66739897\n",
      "  -0.51535851]\n",
      " [ 0.81699383  1.25540975  1.45893551 ... -1.19829693 -0.66739897\n",
      "   3.25839635]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train >>\\n\",X_train,\n",
    "      \"\\nX_test >>\\n\",X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()   # Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=140, activation='relu')) # Adding the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=70, activation='relu')) # Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=35, activation='relu')) # adding the third hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu')) # Adding the fourth hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "134/134 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.8781\n",
      "Epoch 2/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9521\n",
      "Epoch 3/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9688\n",
      "Epoch 4/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9850\n",
      "Epoch 5/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9934\n",
      "Epoch 6/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9977\n",
      "Epoch 7/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 8/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 9/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 8.2730e-04 - accuracy: 0.9998\n",
      "Epoch 10/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 5.3469e-04 - accuracy: 0.9998\n",
      "Epoch 11/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.4046e-04 - accuracy: 1.0000\n",
      "Epoch 12/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6827e-04 - accuracy: 1.0000\n",
      "Epoch 13/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2813e-04 - accuracy: 1.0000\n",
      "Epoch 14/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 9.8649e-05 - accuracy: 1.0000\n",
      "Epoch 15/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 7.9041e-05 - accuracy: 1.0000\n",
      "Epoch 16/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 6.4361e-05 - accuracy: 1.0000\n",
      "Epoch 17/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 5.3210e-05 - accuracy: 1.0000\n",
      "Epoch 18/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 4.5118e-05 - accuracy: 1.0000\n",
      "Epoch 19/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.8312e-05 - accuracy: 1.0000\n",
      "Epoch 20/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.2835e-05 - accuracy: 1.0000\n",
      "Epoch 21/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.8618e-05 - accuracy: 1.0000\n",
      "Epoch 22/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.4846e-05 - accuracy: 1.0000\n",
      "Epoch 23/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.1927e-05 - accuracy: 1.0000\n",
      "Epoch 24/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9206e-05 - accuracy: 1.0000\n",
      "Epoch 25/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6958e-05 - accuracy: 1.0000\n",
      "Epoch 26/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5041e-05 - accuracy: 1.0000\n",
      "Epoch 27/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3388e-05 - accuracy: 1.0000\n",
      "Epoch 28/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1983e-05 - accuracy: 1.0000\n",
      "Epoch 29/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0697e-05 - accuracy: 1.0000\n",
      "Epoch 30/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 9.5771e-06 - accuracy: 1.0000\n",
      "Epoch 31/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 8.6647e-06 - accuracy: 1.0000\n",
      "Epoch 32/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 7.7744e-06 - accuracy: 1.0000\n",
      "Epoch 33/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 7.0602e-06 - accuracy: 1.0000\n",
      "Epoch 34/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 6.3694e-06 - accuracy: 1.0000\n",
      "Epoch 35/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 5.7773e-06 - accuracy: 1.0000\n",
      "Epoch 36/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 5.2377e-06 - accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 4.7708e-06 - accuracy: 1.0000\n",
      "Epoch 38/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 4.3432e-06 - accuracy: 1.0000\n",
      "Epoch 39/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.9567e-06 - accuracy: 1.0000\n",
      "Epoch 40/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.6050e-06 - accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.2921e-06 - accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.0058e-06 - accuracy: 1.0000\n",
      "Epoch 43/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.7464e-06 - accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.5129e-06 - accuracy: 1.0000\n",
      "Epoch 45/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.3017e-06 - accuracy: 1.0000\n",
      "Epoch 46/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.1151e-06 - accuracy: 1.0000\n",
      "Epoch 47/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9378e-06 - accuracy: 1.0000\n",
      "Epoch 48/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.7738e-06 - accuracy: 1.0000\n",
      "Epoch 49/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.6326e-06 - accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.4971e-06 - accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3766e-06 - accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2643e-06 - accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1656e-06 - accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0706e-06 - accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 9.8735e-07 - accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 9.0761e-07 - accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 8.3717e-07 - accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 7.7032e-07 - accuracy: 1.0000\n",
      "Epoch 59/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 7.1055e-07 - accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 6.5503e-07 - accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 6.0518e-07 - accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 5.5867e-07 - accuracy: 1.0000\n",
      "Epoch 63/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 5.1528e-07 - accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 4.7592e-07 - accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 4.3953e-07 - accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 4.0649e-07 - accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.7533e-07 - accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.4709e-07 - accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 3.2015e-07 - accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.9644e-07 - accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.7392e-07 - accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.5307e-07 - accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.3413e-07 - accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.1677e-07 - accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9966e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x178086f08e0>"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 75) # Fitting the ANN to the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [7.0128204e-20],\n",
       "       [1.6590126e-06],\n",
       "       ...,\n",
       "       [8.0798153e-11],\n",
       "       [2.2130691e-11],\n",
       "       [2.3471596e-09]], dtype=float32)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred  = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[854  23]\n",
      " [ 45 143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)   # ACCURACY IN ~= 93.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1065"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(sum(cm))\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erro = cm[0,1] + cm[1,0]\n",
    "erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.6150234741784"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = ((erro*(-100))/total)+100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "992045062d2ba229af4ec824f82107cca7e9d55201820b293f31bdaf1440c28b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('machine': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
