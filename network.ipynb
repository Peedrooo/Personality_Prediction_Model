{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personality prediction model \n",
    "This notebook is used to train a model to predict the personality of a user. For see the results of each line, see the archive network on the folder draft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = str (Path(os.getcwd())) + '\\\\data\\\\data.csv' # finding database\n",
    "data = pd.read_csv(place, sep='\\t')                  # opening database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()                                    # copying database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['dateload'], axis=1, inplace=True)       # dropping dateload column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = ~( (df['IE'] == 0 ) | (df['IE'] == 3) | (df['gender'] == 0) )        # Filter for remove invalid rows in column IE and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[filt]                           # Applying filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing DataFrame\n",
    "\n",
    "intcolumns = df.columns.drop('country')\n",
    "df[intcolumns] = df[intcolumns].astype(np.int8)\n",
    "df['country'] = df['country'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding the \"country\" and \"IE\" column\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['country'] = le.fit_transform(df['country'].values)\n",
    "df['IE'] = le.fit_transform(df['IE'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting data in parameters and target\n",
    "\n",
    "X = df.iloc[:, 0:280].values        # all columns except the last one\n",
    "y = df.iloc[:,280].values           # getting the last column(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train >>\n",
      " [[-1.90397584  0.83617006  0.01460497 ... -1.19829693  1.47572684\n",
      "  -0.51535851]\n",
      " [ 0.81699383 -1.60304267 -0.10802687 ...  0.66796069 -0.66739897\n",
      "  -0.76694216]\n",
      " [ 0.81699383  1.21729705  1.41805823 ... -1.19829693 -0.66739897\n",
      "   0.23939247]\n",
      " ...\n",
      " [-1.22373342 -1.06946489 -1.63411196 ...  0.66796069  1.47572684\n",
      "   0.32325368]\n",
      " [-0.54349101  0.72183196 -0.74843758 ...  0.66796069  1.47572684\n",
      "  -0.85080338]\n",
      " [-1.22373342  0.34070497  0.91390512 ...  0.66796069 -0.66739897\n",
      "  -0.76694216]] \n",
      "X_test >>\n",
      " [[-0.54349101 -0.11664741  1.49981279 ...  0.66796069 -0.66739897\n",
      "  -0.51535851]\n",
      " [ 0.81699383 -0.15476011 -0.72118606 ...  0.66796069 -0.66739897\n",
      "  -0.68308094]\n",
      " [ 0.81699383  1.44597324  0.6141384  ...  0.66796069 -0.66739897\n",
      "   0.74255978]\n",
      " ...\n",
      " [ 0.13675141 -0.26909821 -0.42141934 ... -1.19829693 -0.66739897\n",
      "  -0.51535851]\n",
      " [ 0.81699383  0.41693037 -0.20340719 ... -1.19829693 -0.66739897\n",
      "  -0.51535851]\n",
      " [ 0.81699383  1.25540975  1.45893551 ... -1.19829693 -0.66739897\n",
      "   3.25839635]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train >>\\n\",X_train,\n",
    "      \"\\nX_test >>\\n\",X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()   # Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=70, activation='relu')) # Adding the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=35, activation='relu')) # Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=15, activation='relu')) # adding the third hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=3, activation='relu')) # Adding the fourth hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0745 - accuracy: 0.3969\n",
      "Epoch 2/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.5961\n",
      "Epoch 3/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.7623\n",
      "Epoch 4/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.8638\n",
      "Epoch 5/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.9122\n",
      "Epoch 6/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.9317\n",
      "Epoch 7/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.9392\n",
      "Epoch 8/8\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d819666d00>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 8) # Fitting the ANN to the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80550265],\n",
       "       [0.29992992],\n",
       "       [0.29992992],\n",
       "       ...,\n",
       "       [0.3069834 ],\n",
       "       [0.30590743],\n",
       "       [0.29992992]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred  = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[834  43]\n",
      " [ 34 154]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1065"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(sum(cm))\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erro = cm[0,1] + cm[1,0]\n",
    "erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.98591549295774"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = ((erro*(-100))/total)+100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f859f1efcb3e46a263fe37ee3fce2a1200fa18748cc2f3fcc4b4ee8efe6f93c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
